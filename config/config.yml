image_size: 64
batch_size: 64
eval_seed: 175
eval_batch_size: 8
num_epochs: 50
num_training_steps: 1000
num_inference_steps: 100
save_every_epoch: 1
logger: wandb

optimizer: AdamW
optimizer_params:
  weight_decay: 0 

dataset_dir: dataset
checkpoint_dir: checkpoint
load_checkpoint: model_2024-11-29_16-02-19.pt
output_dir: output
scheduler: OneCycleLR
lr_initial: 1.e-5
max_lr: 5.e-5
total_steps: 30000
pct_start: 0.001
anneal_strategy: linear
clip_grad_norm: 1.0    
